---
title: "SEISMIC Equity Measures"
subtitle: "Outcome: Grades"
author: "Victoria Farrar"
date: "2023-03-03"
output:
  rmdformats::readthedown
css:
  custom.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warnings = FALSE, messages = FALSE)
setwd("~/Documents/GitHub/LAK-sandbox/")
syndat <- read.csv(file = "SEISMIC_synthetic_data_2023-01-26.csv")
library(tidyverse)
library(gmodels) #ci
library(rmdformats)
library(kableExtra) #prettier html tables
library(lme4) #mixed models
library(lmerTest) #significance for mixed models
library(parameters) #pretty model output for .Rmd
```

# Academic Factors

## Question: How does overall prior performance at the university compare to student outcomes in my course?

### Grade anomaly

**Grade anomaly** is a way we can compare outcomes in our course to students' other experiences at the university. Often, to compare, we use grade point average omitting the course of interest (GPAO), because this metric has been found to be the best metric of prior academic preparation in previous studies (compared to high school GPA or standardized test scores, [Koester et al.,2016](https://doi.org/10.48550/arXiv.1608.07565)).

Grade anomaly has two key advantages:

1)  It provides a relative view of a course grade relative to a students' other course outcomes. Essentially, it places the grade in context of the student's general performance. Since students relative grades (i.e. *How am I doing in this class relative to my others?*) can affect their persistence in STEM, for instance ([Ost, 2010](https://www.sciencedirect.com/science/article/abs/pii/S0272775710000762?via%3Dihub); [Witteveen & Atwell, 2020](https://onlinelibrary.wiley.com/doi/full/10.1002/sce.21580) ) this context can be important for understanding the impacts of a course on retention in STEM.

2)  It allows us to "normalize" against a students' grade in a single course against their previous grades within an institutional context. This allows us to compare across courses, departments and institutions, while "normalizing" for differences in grading norms across those contexts (Matz et al., 2017).

Grade anomalies can be:

-   **Grade penalties** - where students receive *lower* grades in the course relative to their other coursework, or,

-   **Grade bonuses** - where students receive *higher* grades relative to other courses.

### Example

```{r avg grade anomaly (aga), warning=FALSE, message=FALSE}
#show average grade anomaly across all sections of courses in dataset

aga <- #average grade anomaly
syndat %>% 
  drop_na(numgrade, gpao) %>%
  mutate(grade_anomaly = numgrade - gpao) %>%
  group_by(crs_name) %>%
  summarise(mean = gmodels::ci(grade_anomaly)[1], 
                      lowCI = gmodels::ci(grade_anomaly)[2],
                      hiCI = gmodels::ci(grade_anomaly)[3], 
                      sd = gmodels::ci(grade_anomaly)[4])

kable_styling(kbl(aga, digits = 2))

#plot
ggplot(aga, aes(x = crs_name, y = mean, color = crs_name)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = lowCI, ymax = hiCI)) + 
  geom_hline(yintercept = 0) + 
  labs(x = NULL, y = "Mean Grade Anomaly \n(Course Grade - GPAO)",
       color = "Course") + 
  theme_classic()


```

In the synthetic data, we can see that there is a **grade penalty** for all upper division courses examined. This means that students are doing *worse* on average in all of these courses compared to other courses taken at the university. However, we can see that organic chemistry seems to be have significantly lower grade outcomes than say, Evolutionary Biology or Statistics.

[WOULD GUIDING QUESTIONS BE BETTER HERE, RATHER THAN AN ACTUAL WALKTHROUGH?]{style="color: red;"}

## What do these trends look like across time?

We can also examine how grade anomaly has changed (or not) in a course over time.

### Example

```{r aga over time, message=FALSE, warning=FALSE}
#plot average grade anomaly over years
syndat %>% 
  drop_na(numgrade, gpao) %>%
  mutate(grade_anomaly = numgrade - gpao) %>%
  mutate(year = str_sub(crs_section,0,4)) %>%
  ggplot(aes(x = year, y = grade_anomaly, color = crs_name)) + 
  stat_summary(geom = "point", fun.y = "mean", position = position_dodge(0.25)) + 
  stat_summary(geom = "errorbar", fun.data = "mean_cl_normal", width = 0.2, position = position_dodge(0.25)) + 
  labs(x = "Year", y = "Average grade anomaly", color = "Course") + 
  theme_bw()

```

For instance, we can see that Evolutionary Biology had a larger grade penalty in 2018 than in 2019. The grade penalty has been getting smaller over time in Biology 300 from 2016 to 2019.

# Demographic Factors

An important next question to ensure equitable outcomes is to examine grade anomaly for students from diverse backgrounds in STEM. These include identities such as gender, race/ethnicity, first-generation college-going status, and low income status.

Ideally, students from historically marginalized groups will not have larger grade penalties than students from majority groups, and may even sometimes experience grade bonuses.

## What is the makeup of the course student body?

Before answering this question, we should evaluate the makeup of the student body. Who even takes these courses?

```{r demographics overview}
#return percents of all demographic groups
syndat %>%
  group_by(crs_name) %>%
  summarise(n = n(), 
            percent_women = sum(female)/n*100, 
            percent_PEER = sum(ethniccode_cat == "1")/n*100, 
            percent_firstgen = sum(firstgen)/n*100,
            percent_lowincome = sum(lowincomeflag)/n*100) %>%
  kbl(., digits = 1) %>%
  kable_styling()
```

## How does grade anomaly compare for students from historically marginalized groups in STEM?

```{r aga by demographics}
syndat %>%
  pivot_longer(cols = female:lowincomeflag, 
               names_to = "demo_var",
               values_to = "value") %>%
  filter(value == 1 & demo_var != "transfer") %>%
  mutate(demo_var = factor(demo_var, 
                           labels = c("PEER", "Woman", "FirstGen", "LowIncome", "International"))) %>%
  ggplot(aes(x = demo_var, y = numgrade-gpao, color = crs_name)) + 
  stat_summary(geom = "point", fun = "mean") + 
  stat_summary(geom = "errorbar", fun.data = "mean_cl_normal", width = 0.1) + 
  labs(x = "Student identity", y = "Average grade anomaly", color = "Course",
       subtitle = "Mean Â± 95% CI shown") + 
  theme_bw()
```

We observe that while all students receive grade penalties in these courses, Chemistry & Biology lead to significantly larger grade penalties for almost all identities (PEER students, women, first-generation students, and low income students, international students) compared to Evolutionary Biology & Statistics.

## Linear modeling

[*NOTE: I would want Montse to look over this section as she teaches stats!*]{style="color: red;"}

Another common approach to exploring the relationship between student identities and course grade outcomes is linear modeling, or linear regression. Here, we set the course grade as the dependent variable, and all demographic variables as independent variables. This approach allows us to quantify how much each axis of student identity explains variation in course grades *while controlling for other demographic identities*. Following our focus so far on grade anomaly, our model could look like this:

$GradeAnomaly \sim \beta Gender + \beta PEER + \beta FirstGen + \beta Low Income + \beta International + \epsilon$

It's also important to control for variation in the course across offerings, as each offering can differ in the student population (who is taking the course? are they taking it "on" schedule or "off" the typical curricular schedule?), instruction (who teaches the course? what are the grading policies? what topics were covered?) and other factors (for example, what quarter the course was taken can affect student breaks, schedules, etc.). To control for this, researchers often add a *random effect* of course offering. Models including random and fixed effects (what we typically think of as "regular" independent variables) are called **linear mixed models**. To learn more about random effects and mixed models, see the great resource in [Theobald 2018](https://doi.org/10.1187/cbe.17-12-0280).

Model now with random effects:

$GradeAnomaly \sim \beta Gender + \beta PEER + \beta FirstGen + \beta Low Income + \beta International + U (1|CourseOffering) + \epsilon$

Let's explore the linear mixed model for just BIO 300.

[(*NOTE: I do not love the output of `parameters` package currently, working on using `sjPlot` instead.*)]{style="color: red;"}

```{r aga lm}
#calculate grade anomaly in dataset
syndat$grade_anomaly <- syndat$numgrade - syndat$gpao

#subset data to just bio300
bio300 <- syndat %>% filter(crs_name == "BIO300")

#build model
model1 <- lmer(grade_anomaly ~ female + as.factor(ethniccode_cat) + firstgen + lowincomeflag + international + (1|crs_section) , data = bio300)

```

```{r print model parameters, echo=FALSE}
mp <- model_parameters(model1, digits = 2, p_digits = 3) 
print_html(mp)
```

### What does this model output tell us?

The coefficient refers to the \$\beta , which is the amount of variation in *GradeAnomaly* that is explained by the variable of interest, all other factors held constant. The standard error for this coefficient, as well as the 95% confidence interval (CI) are shown to the left. Then, the *t*-value and *p*-value for this coefficient is shown. Typically, coefficients that are significantly different from zero (i.e., actually explain a portion of the variation in our dependent variable) will have confidence intervals that do not include 0 and *p* \< 0.05.

What we see is that in BIO300, being a PEER student (`ethniccode_cat` = 1) has the largest impact on grade anomaly, making the grade penalty -0.21 points lower for PEER students (all other variables held constant). After this, the next most impacted group is women, for whom the model predicts will have a grade penalty - 0.12 points lower than men with all other variables held constant.

We can play around with these model parameters to understand what the model is telling us. Set the demographic variables to the variables you care about in the chunk below:

```{r enter demog vars for lm}
#enter 0 for "no" and 1 for "yes"
peer <- 1
woman <- 1
firstgen <- 1
lowincome <- 1
interntnl <-0

expected_grade_anomaly <- -0.22 + -0.12*woman + -0.21*peer -0.09*firstgen -0.06*lowincome  + 0.02*interntnl

print(paste("expected grade anomaly =", expected_grade_anomaly))
```

## How does grade anomaly relate to the systemic advantages in higher education a student may hold?

How can we view the cumulative effect of systemic advantages students may have access to (conferred by demographic identities) overall in the context of a course?

## SAI

SAI, or the **Systemic Advantage Index** is one approach. This metric takes into account multiple axes of student identities, including:

-   race/ethnicity

-   gender

-   socioeconomic status

-   parental education (i.e., first-generation college-going status)

------------------------------------------------------------------------

> ðŸ’­ Can you think of any other systemic advantages not included in this index that likely influence student's outcomes in a course? What would be the challenges to adding those identities or advantages to this index?

------------------------------------------------------------------------

```{r SAI calculation, echo=TRUE}
#this code goes through all possible combinations of the 4 advantage axes and assigns an SAI based on that students' values
#as ethniccode_cat == 1 is the "BIPOC" label, all other categories are considered advantaged 
syndat <-
  syndat %>% mutate(sai = case_when(
    female == "0" & ethniccode_cat != "1" & firstgen == "0" & lowincomeflag == "0"  ~ "4",
    female == "1" & ethniccode_cat != "1" & firstgen == "0" & lowincomeflag == "0"  ~ "3",
    female == "0" & ethniccode_cat == "1" & firstgen == "0" & lowincomeflag == "0"  ~ "3", 
    female == "0" & ethniccode_cat != "1" & firstgen == "0" & lowincomeflag == "1"  ~ "3", 
    female == "0" & ethniccode_cat != "1" & firstgen == "1" & lowincomeflag == "0"  ~ "3", 
    female == "0" & ethniccode_cat == "1" & firstgen == "1" & lowincomeflag == "0"  ~ "2", 
    female == "0" & ethniccode_cat == "1" & firstgen == "0" & lowincomeflag == "1"  ~ "2", 
    female == "1" & ethniccode_cat == "1" & firstgen == "0" & lowincomeflag == "0"  ~ "2", 
    female == "0" & ethniccode_cat != "1" & firstgen == "1" & lowincomeflag == "1"  ~ "2", 
    female == "1" & ethniccode_cat != "1" & firstgen == "1" & lowincomeflag == "0"  ~ "2", 
    female == "1" & ethniccode_cat != "1" & firstgen == "0" & lowincomeflag == "1"  ~ "2", 
    female == "1" & ethniccode_cat != "1" & firstgen == "1" & lowincomeflag == "1"  ~ "1", 
    female == "1" & ethniccode_cat == "1" & firstgen == "1" & lowincomeflag == "0"  ~ "1",
    female == "1" & ethniccode_cat == "1" & firstgen == "0" & lowincomeflag == "1"  ~ "1", 
    female == "0" & ethniccode_cat == "1" & firstgen == "1" & lowincomeflag == "1"  ~ "1",
    female == "1" & ethniccode_cat == "1" & firstgen == "1" & lowincomeflag == "1"  ~ "0",
    TRUE ~ "NA"))
```

### How are students distributed across SAI? (What systemic advantages do my students have access to)?
```{r sample size by SAI}
#sample size by SAI
```

Let us examine trends in grade anomaly across the SAI. 

```{r SAI plot}
#plot raw grades in course of interest
syndat %>%
  ggplot(aes(x = sai, y = numgrade-gpao, color = crs_name))+ 
      stat_summary(geom = "point", fun = "mean", 
                 position = position_dodge(0.2)) + 
    stat_summary(geom = "errorbar", fun.data = "mean_cl_normal", 
                 width = 0.1, position = position_dodge(0.2)) +
  labs(x = "SAI", y = "Average grade anomaly", color = "Course") + 
  theme_bw()

syndat %>%
  ggplot(aes(x = sai, y = numgrade-gpao, color = crs_name))+ 
      stat_summary(geom = "point", fun = "mean") + 
    stat_summary(geom = "errorbar", fun.data = "mean_cl_normal", width = 0.1) +
  labs(x = "SAI", y = "Average grade anomaly", color = "Course",
       subtitle = "Mean Â± 95% CI shown") + 
  theme_bw()
```
Comparing the figures where we examined trends in grade anomaly across specific demographic identities, versus a view across systemic advantages, what can we observe from this graph? 

The SAI approach makes it clear that as students have increasing numbers of systemic advantages in higher education, they tend to receive less of a grade penalty in these courses. This overall pattern is obvious across all four courses, although the effect of increasing advantages may taper in some courses between groups 3 & 4. 


# Environmental Factors
